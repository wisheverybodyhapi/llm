{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65e7b51f",
   "metadata": {},
   "source": [
    "# 下载数据集，并对数据集进行处理！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09d8b82",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 1. 下载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90f7952f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集结构：\n",
      "train: Dataset({\n",
      "    features: ['instruction', 'input', 'output', 'history'],\n",
      "    num_rows: 799743\n",
      "})\n",
      "\n",
      "训练集大小: 799743\n",
      "\n",
      "数据集的特征：\n",
      "{'instruction': Value(dtype='string', id=None), 'input': Value(dtype='string', id=None), 'output': Value(dtype='string', id=None), 'history': Value(dtype='null', id=None)}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_path = \"/raid/gfc/llm/datasets/Chinese-medical-dialogue\"\n",
    "ds = load_dataset(\"ticoAg/Chinese-medical-dialogue\", cache_dir=dataset_path)\n",
    "\n",
    "# 查看数据集的基本信息\n",
    "print(\"数据集结构：\")\n",
    "for k, v in ds.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# 获取数据集的大小\n",
    "print(f\"\\n训练集大小: {len(ds['train'])}\")\n",
    "\n",
    "# 查看数据集的列名（特征）\n",
    "print(\"\\n数据集的特征：\")\n",
    "print(ds['train'].features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e8f3fc",
   "metadata": {},
   "source": [
    "### 2. 清洗数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37186d15",
   "metadata": {},
   "source": [
    "##### 2.1 缺失值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b32fe0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始样本数: 799743\n",
      "清洗后样本数: 799736\n",
      "{'instruction': '小儿肥胖超重该如何治疗', 'input': '女宝宝，刚7岁，这一年，察觉到，我家孩子身上肉很多，而且，食量非常的大，平时都不喜欢吃去玩，请问：小儿肥胖超重该如何治疗。', 'output': '孩子出现肥胖症的情况。家长要通过孩子运功和健康的饮食来缓解他的症状，可以先让他做一些有氧运动，比如慢跑，爬坡，游泳等，并且饮食上孩子多吃黄瓜，胡萝卜，菠菜等，禁止孩子吃一些油炸食品和干果类食物，这些都是干热量高脂肪的食物，而且不要让孩子总是吃完就躺在床上不动，家长在治疗小儿肥胖期间如果孩子情况严重就要及时去医院在医生的指导下给孩子治疗。', 'history': None}\n",
      "小儿肥胖超重该如何治疗\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "# 数据清洗\n",
    "def is_valid(example):\n",
    "    # 三项都不能为空且不是纯空格\n",
    "    return all([\n",
    "        example['instruction'] and example['instruction'].strip(),\n",
    "        example['input'] and example['input'].strip(),\n",
    "        example['output'] and example['output'].strip()\n",
    "    ])\n",
    "\n",
    "dataset = ds['train']\n",
    "print(f\"原始样本数: {len(dataset)}\")\n",
    "\n",
    "# 过滤空值\n",
    "ds_clean = dataset.filter(is_valid)\n",
    "print(f\"清洗后样本数: {len(ds_clean)}\")\n",
    "\n",
    "print(ds_clean[0])\n",
    "print(ds_clean[0]['instruction'])\n",
    "print(type(ds_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e530ba55",
   "metadata": {},
   "source": [
    "##### 2.2 格式化规范\n",
    "去除多余空格、特殊符号。\n",
    "统一全角/半角、简繁体（如有需要）。\n",
    "统一标点符号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f036a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 799736/799736 [03:01<00:00, 4398.32 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据格式化完成！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import jaconv\n",
    "from zhconv import convert\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5a-zA-Z0-9，。！？、；：“”‘’（）《》【】]', '', text)\n",
    "    text = jaconv.z2h(text, kana=False, ascii=True, digit=True)\n",
    "    text = convert(text, 'zh-cn')\n",
    "    return text\n",
    "\n",
    "def normalize_example(example):\n",
    "    for col in ['instruction', 'input', 'output']:\n",
    "        example[col] = normalize_text(str(example[col]))\n",
    "    return example\n",
    "\n",
    "# 推荐：直接在 HuggingFace Dataset 上并行处理\n",
    "ds_clean = ds_clean.map(normalize_example, num_proc=4)  # 可根据CPU核数调整num_proc\n",
    "\n",
    "print(\"数据格式化完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55df9c5",
   "metadata": {},
   "source": [
    "##### 2.3 去除冗余数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76037d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重后样本数: 752436\n",
      "近似去重后样本数: 750026\n"
     ]
    }
   ],
   "source": [
    "# 去重（以instruction+input+output为唯一标识）\n",
    "import pandas as pd\n",
    "from simhash import Simhash\n",
    "\n",
    "df = ds_clean.to_pandas()\n",
    "df = df.drop_duplicates(subset=['instruction', 'input', 'output'])\n",
    "print(f\"去重后样本数: {len(df)}\")\n",
    "\n",
    "# 近似去重示例（SimHash）\n",
    "def get_simhash(text):\n",
    "    return Simhash(text).value\n",
    "\n",
    "df['simhash'] = df.apply(lambda row: get_simhash(row['instruction'] + row['input'] + row['output']), axis=1)\n",
    "df = df.drop_duplicates(subset=['simhash'])\n",
    "print(f\"近似去重后样本数: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6110b384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 800/800 [00:16<00:00, 48.12ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "格式化后的数据集已保存到: /raid/gfc/llm/datasets/Chinese-medical-dialogue/formatted_dataset(quchong+simhash).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 存储格式化以后的数据集\n",
    "formated_dataset_path = os.path.join(dataset_path, \"formatted_dataset(quchong+simhash).csv\")\n",
    "\n",
    "ds_clean.to_csv(formated_dataset_path, index=False, encoding='utf-8')\n",
    "print(f\"格式化后的数据集已保存到: {formated_dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab5e3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可选：过滤过短/过长\n",
    "df = df[df['input'].str.len() < 5]\n",
    "df = df[df['output'].str.len() < 5]\n",
    "\n",
    "# 保存清洗后的数据\n",
    "df.to_csv(\"/raid/gfc/llm/datasets/Chinese-medical-dialogue/cleaned_train.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13949b25",
   "metadata": {},
   "source": [
    "### 3. 处理数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cd3ad7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
